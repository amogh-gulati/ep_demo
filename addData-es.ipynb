{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import tweepy\n",
    "import os\n",
    "import json\n",
    "from elasticsearch import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the server\n",
    "es = Elasticsearch(HOST = \"localhost\", PORT = 9200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check connection\n",
    "if not es.ping():\n",
    "    raise ValueError(\"elasticsearch connection failed\")\n",
    "else:\n",
    "    print(\"elasticsearch connection successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "  \"settings\": {\n",
    "    \"number_of_shards\": 1,\n",
    "    \"number_of_replicas\": 0,\n",
    "    \"index.mapping.total_fields.limit\": 2000,\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"nlp_analyzer\": {\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"tweeter_tokenizer\",\n",
    "          \"filter\": [\"lowercase\"]\n",
    "        }\n",
    "      },\n",
    "      \"tokenizer\": {\n",
    "        \"tweeter_tokenizer\": {\n",
    "          \"type\": \"pattern\",\n",
    "          \"pattern\": \"(\\\\w+|\\\\S*[\\\\S*])\",\n",
    "          \"group\": 1\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },  \n",
    "    \"mappings\": {\n",
    "      \"properties\": {\n",
    "        \"sentiment_score\": {\n",
    "          \"type\": \"float\"\n",
    "        },\n",
    "        \"sentiment\" : {\n",
    "          \"type\": \"keyword\"\n",
    "        },\n",
    "        \"created_at\": {\n",
    "          \"type\":   \"date\",\n",
    "          \"format\": \"EEE MMM dd HH:mm:ss Z yyyy\"\n",
    "        },\n",
    "        \"retweeted_status.created_at\": {\n",
    "          \"type\":   \"date\",\n",
    "          \"format\": \"EEE MMM dd HH:mm:ss Z yyyy\"\n",
    "        },\n",
    "      \n",
    "      \"user.created_at\": {\n",
    "          \"type\":   \"date\",\n",
    "          \"format\": \"EEE MMM dd HH:mm:ss Z yyyy\"\n",
    "      },\n",
    "      \"retweeted_status.user.created_at\": {\n",
    "          \"type\":   \"date\",\n",
    "          \"format\": \"EEE MMM dd HH:mm:ss Z yyyy\"\n",
    "      },\n",
    "      \"coordinates.coordinates\": {\n",
    "          \"type\": \"geo_point\"\n",
    "        },\n",
    "      \"place.bounding_box\": {\n",
    "          \"type\": \"geo_shape\",\n",
    "          \"coerce\": True,\n",
    "          \"ignore_malformed\": True\n",
    "        } \n",
    "      }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIndex(name,mappings):\n",
    "    if not es.indices.exists(index = name):\n",
    "        res = es.indices.create(index = name ,body = mappings ,ignore = 400)\n",
    "        print(res)\n",
    "        if 'acknowledged' not in res.keys() or res['acknowledged'] != True or res['index'] != name: \n",
    "            raise ValueError(\"index creating failed\")\n",
    "        else:\n",
    "            print(name,\":index created successfully\")\n",
    "    else:\n",
    "        print(\"index exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the index (database name)\n",
    "#EDIT NAME HERE\n",
    "index_name = \"twitter-corona-test-amogh\"\n",
    "createIndex(index_name,mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweepy stuff\n",
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"\"\n",
    "OAUTH_TOKEN = \"\"\n",
    "OAUTH_TOKEN_SECRET =  \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the data\n",
    "files = os.listdir('data/')\n",
    "print(files)\n",
    "for f in files:\n",
    "    ids = open(\"data/\"+f)\n",
    "    ids = ids.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_list = ids[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MAKE CHANGES HERE - GIVE HELPER.BULK A LIST OF TWEET JSONS AT A TIME - \n",
    "max_count = 100\n",
    "total_count = 0\n",
    "count = 0\n",
    "id_list = []\n",
    "sent_list = []\n",
    "tweets = []\n",
    "for id in ids_list:\n",
    "    id = id.split(\",\")\n",
    "    sentiment = float(id[1])\n",
    "    id = int(id[0])\n",
    "#     print(id,sentiment)\n",
    "    id_list.append(id)\n",
    "    sent_list.append(sentiment)\n",
    "    count = count + 1\n",
    "    total_count = total_count + 1\n",
    "    if count == max_count:\n",
    "        tweets = api.statuses_lookup(id_list)\n",
    "        tweets = [i._json for i in tweets]\n",
    "        for i in range(len(tweets)):\n",
    "            tweets[i][\"sentiment_score\"] = id_list[i]\n",
    "            tweets[i][\"_index\"] = \"twitter-corona-test-amogh\"\n",
    "        res = helpers.bulk(es, tweets)\n",
    "        print(res)\n",
    "        print(total_count,\"done\")\n",
    "        count = 0\n",
    "        tweets = []\n",
    "        id_list = []\n",
    "        sent_list = []\n",
    "tweets = api.statuses_lookup(id_list)\n",
    "tweets = [i._json for i in tweets]\n",
    "for i in range(len(tweets)):\n",
    "    tweets[i][\"sentiment_score\"] = id_list[i]\n",
    "    tweets[i][\"_index\"] = \"twitter-corona-test-amogh\"\n",
    "helpers.bulk(es, tweets)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please dont use this recklessly\n",
    "#es.indices.delete(index='twitter-corona-test-amogh', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
