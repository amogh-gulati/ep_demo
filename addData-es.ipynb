{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import tweepy\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from elasticsearch import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the server\n",
    "es = Elasticsearch(HOST = \"localhost\", PORT = 9200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch connection successful\n"
     ]
    }
   ],
   "source": [
    "#check connection\n",
    "if not es.ping():\n",
    "    raise ValueError(\"elasticsearch connection failed\")\n",
    "else:\n",
    "    print(\"elasticsearch connection successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "  \"settings\": {\n",
    "    \"number_of_shards\": 1,\n",
    "    \"number_of_replicas\": 0,\n",
    "    \"index.mapping.total_fields.limit\": 5000,\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"nlp_analyzer\": {\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"tweeter_tokenizer\",\n",
    "          \"filter\": [\"lowercase\"]\n",
    "        }\n",
    "      },\n",
    "      \"tokenizer\": {\n",
    "        \"tweeter_tokenizer\": {\n",
    "          \"type\": \"pattern\",\n",
    "          \"pattern\": \"(\\\\w+|\\\\S*[\\\\S*])\",\n",
    "          \"group\": 1\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },  \n",
    "    \"mappings\": {\n",
    "      \"properties\": {\n",
    "        \"sentiment\" : {\n",
    "          \"type\": \"keyword\"\n",
    "        },\n",
    "        \"created_at\": {\n",
    "          \"type\":   \"date\",\n",
    "          \"format\": \"EEE MMM dd HH:mm:ss Z yyyy\"\n",
    "        },\n",
    "        \"id_str\":{\n",
    "            \"type\" : \"keyword\"\n",
    "        },\n",
    "        \"text\":{\n",
    "            \"type\" : \"text\"\n",
    "        },\n",
    "        \"user_account_created_at\": {\n",
    "            \"type\":   \"date\",\n",
    "            \"format\": \"EEE MMM dd HH:mm:ss Z yyyy\"\n",
    "        },\n",
    "        \"user_id\":{\n",
    "            \"type\": \"keyword\"\n",
    "        },\n",
    "        \"screen_name\":{\n",
    "            \"type\": \"keyword\"\n",
    "        },\n",
    "        \"user_followers_count\":{\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"user_friends_count\":{\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"coordinates.coordinates\": {\n",
    "            \"type\": \"geo_point\"\n",
    "        },\n",
    "        \"place.bounding_box\": {\n",
    "          \"type\": \"geo_shape\",\n",
    "          \"coerce\": True,\n",
    "          \"ignore_malformed\": True\n",
    "        },\n",
    "        \"user_coordinates\":{\n",
    "          \"type\": \"geo_point\"\n",
    "        },\n",
    "        \"user_statuses_count\":{\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"tweet_length\":{\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"favorite_count\":{\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"retweet_count\":{\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"hashtags\": {\n",
    "          \"type\": \"keyword\"\n",
    "        },\n",
    "        \"author_description\":{\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"is_author_verified\": {\n",
    "              \"type\": \"boolean\"\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIndex(name,mappings):\n",
    "    if not es.indices.exists(index = name):\n",
    "        res = es.indices.create(index = name ,body = mappings ,ignore = 400)\n",
    "        print(res)\n",
    "        if 'acknowledged' not in res.keys() or res['acknowledged'] != True or res['index'] != name: \n",
    "            raise ValueError(\"index creating failed\")\n",
    "        else:\n",
    "            print(name,\":index created successfully\")\n",
    "    else:\n",
    "        print(\"index exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'twitter-depression-analysis-group3'}\n",
      "twitter-depression-analysis-group3 :index created successfully\n"
     ]
    }
   ],
   "source": [
    "#create the index (database name)\n",
    "#EDIT NAME HERE\n",
    "index_name = \"twitter-depression-analysis-group3\"\n",
    "createIndex(index_name,mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweepy stuff\n",
    "# CONSUMER_KEY = \"\"\n",
    "# CONSUMER_SECRET = \"\"\n",
    "# OAUTH_TOKEN = \"\"\n",
    "# OAUTH_TOKEN_SECRET =  \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "# auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "# api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the data\n",
    "# file = '../data/anchor_tweets.json'\n",
    "# print(file)\n",
    "# ids_list = []\n",
    "# f = open(file,'r')\n",
    "# for tweet in f:\n",
    "#         tweet = tweet.strip(\"\\r\\n\")\n",
    "#         tweet = json.loads(tweet)\n",
    "#         ids_list.append(tweet)\n",
    "# f.close()\n",
    "\n",
    "file = \"../data/new_list.pickle\"\n",
    "f = open(file,\"rb\")\n",
    "cnt, ids_list = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9961\n"
     ]
    }
   ],
   "source": [
    "print(len(ids_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimTweets(tweets):\n",
    "    #database is only accepting 1000 fields, only take the data you need\n",
    "    newTweets = []\n",
    "    for t in tweets:\n",
    "        data = {}\n",
    "        data[\"_index\"] = t[\"_index\"]\n",
    "        data[\"created_at\"] = t[\"created_at\"]\n",
    "        data[\"id_str\"] = t[\"id_str\"]\n",
    "        data[\"text\"] = t[\"full_text\"]\n",
    "        data[\"user_account_created_at\"] = t[\"user\"][\"created_at\"]\n",
    "        data[\"user_id\"] = t[\"user\"][\"id\"]\n",
    "        data[\"screen_name\"] = t[\"user\"][\"screen_name\"]\n",
    "        data[\"user_followers_count\"] = t[\"user\"][\"followers_count\"]\n",
    "        data[\"user_friends_count\"] = t[\"user\"][\"friends_count\"]\n",
    "        data[\"coordinates\"] = t[\"coordinates\"]\n",
    "        data[\"place\"] = t[\"place\"]\n",
    "        data[\"user_coordinates\"] = t[\"user_coordinates\"]\n",
    "        data[\"statuses_count\"] = t[\"user\"][\"statuses_count\"]\n",
    "        data[\"tweet_length\"] = len(t[\"full_text\"])\n",
    "        data[\"favorite_count\"] = t[\"favorite_count\"]\n",
    "        data[\"retweet_count\"] = t[\"retweet_count\"]\n",
    "        data[\"hashtags\"] = []\n",
    "        for i in t[\"entities\"][\"hashtags\"]:\n",
    "            data[\"hashtags\"].append(i[\"text\"].lower())\n",
    "        data[\"author_description\"] = t[\"user\"][\"description\"]\n",
    "        data[\"is_author_verified\"] = t[\"user\"][\"verified\"]\n",
    "        newTweets.append(data)\n",
    "    return newTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, [])\n",
      "1000 done\n",
      "(1000, [])\n",
      "2000 done\n",
      "(1000, [])\n",
      "3000 done\n",
      "(1000, [])\n",
      "4000 done\n",
      "(1000, [])\n",
      "5000 done\n",
      "(1000, [])\n",
      "6000 done\n",
      "(1000, [])\n",
      "7000 done\n",
      "(1000, [])\n",
      "8000 done\n",
      "(1000, [])\n",
      "9000 done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##MAKE CHANGES HERE - GIVE HELPER.BULK A LIST OF TWEET JSONS AT A TIME - \n",
    "max_count = 1000\n",
    "total_count = 0\n",
    "count = 0\n",
    "batch_tweets = []\n",
    "for tweet in ids_list:\n",
    "    count = count + 1\n",
    "    total_count = total_count + 1\n",
    "    batch_tweets.append(tweet)\n",
    "    if count == max_count:\n",
    "        for i in range(len(batch_tweets)):\n",
    "#             tweets[i][\"sentiment_score\"] = id_list[i]\n",
    "            batch_tweets[i][\"_index\"] = index_name\n",
    "        batch_tweets = trimTweets(batch_tweets)\n",
    "        res = helpers.bulk(es, batch_tweets)\n",
    "        print(res)\n",
    "        print(total_count,\"done\")\n",
    "        count = 0\n",
    "        batch_tweets = []\n",
    "for i in range(len(batch_tweets)):\n",
    "#     tweets[i][\"sentiment_score\"] = id_list[i]\n",
    "    batch_tweets[i][\"_index\"] = index_name\n",
    "batch_tweets = trimTweets(batch_tweets)\n",
    "helpers.bulk(es, batch_tweets)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#please dont use this recklessly\n",
    "es.indices.delete(index='twitter-depression-analysis-group3', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
